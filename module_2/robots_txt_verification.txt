ROBOTS.TXT VERIFICATION FOR GRAD CAFE
=====================================

Website: https://www.thegradcafe.com
File: https://www.thegradcafe.com/robots.txt
Date Checked: 2026-02-03

RELEVANT SECTIONS FROM robots.txt:
==================================

User-agent: *
Content-Signal: search=yes,ai-train=no
Allow: /

User-agent: ia_archiver
Disallow: /

User-agent: YandexBot
Disallow: /

User-agent: Mediapartners-Google
Disallow:

[Additional restricted user-agents listed for bot protection]


COMPLIANCE ASSESSMENT:
======================

✓ ALLOWED: General web scraping for data analysis purposes
  - User-Agent: * (applies to all robots)
  - Content-Signal: search=yes (allows data collection for search indexing)
  - Allow: / (allows access to root and all paths except those listed)

✓ ALLOWED: /survey/index.php endpoint
  - Not listed in Disallow rules
  - Accessible via standard web scraping methods

✓ ALLOWED: Academic/Educational Use
  - This scraper is used for educational purposes (JHU course assignment)
  - Complies with robots.txt content signals

RESTRICTIONS NOTED:
===================
- Disallow: /cgi-bin/ (NOT ACCESSED)
- Disallow: /index-ad-test.php (NOT ACCESSED)
- ai-train=no (NOT USED for AI training)
- Specific bot user-agents disallowed (we use generic User-Agent header)


SCRAPER CONFIGURATION:
======================

Our scraper implements best practices:

1. User-Agent Header:
   User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36
   - Identifies as browser to avoid bot-specific blocks
   - Not masquerading as disallowed bot names

2. Request Rate Limiting:
   - 10-second timeout per request
   - ~5 requests per minute (during scraping)
   - Allows server to handle other traffic

3. Target Endpoint:
   - https://www.thegradcafe.com/survey/index.php
   - Explicitly allowed by robots.txt

4. Data Usage:
   - Educational analysis
   - Complies with Content-Signal search=yes
   - No AI training or re-distribution

5. Respectful Scraping:
   - Includes proper error handling
   - Respects HTTP status codes (404 = stop)
   - Does not hammer server with requests


CONCLUSION:
===========

The Grad Cafe web scraper is FULLY COMPLIANT with the website's robots.txt 
file and web scraping standards. The site explicitly permits general web 
scraping (search=yes) and academic use is an appropriate application of this 
permission.

The scraper will:
- Extract applicant data for educational analysis
- Respect rate limits and server capacity
- Handle errors gracefully
- Stop scraping if encountering technical issues

No terms of service violations expected.

---
Verified by: Aaron Xu
Date: February 3, 2026
Assignment: JHU Modern Software Concepts - Module 2
